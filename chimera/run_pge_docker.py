#!/usr/bin/env python
"""
Contributors:
- Namrata Malarout
- Michael Cayanan
- Sujen Shah

This is the second step of Chimera
Takes the configuration generated by IPP and creates the HySDS job parameters for job submission
"""

from importlib import import_module

from chimera.logger import logger
from chimera.commons.conf_util import YamlConf
from chimera.pge_job_submitter import PgeJobSubmitter

"""
This is a sample mozart job payload
{
    "job_name": "%s-%s" % (job_type, l0b_lr_raw_id),
    "job_type": "job:%s" % job_type,
    "job_queue": job_queue,
    "container_mappings": container_mappings,
    "soft_time_limit": 86400,
    "time_limit": 86700,
    "payload": {
        # smap_sciflo tracking info
        "_sciflo_wuid": wuid,
        "_sciflo_job_num": job_num,

        # job spec for dependencies
        "job_specification": {
          "digest": "sha256:3debc246c9d86f45a317ae6af4fa82ef9faf1206faf8201ed94db511468d214b", 
          "id": "container-aria-hysds_aria-pdl-clone:master", 
          "url": "s3://s3-us-west-2.amazonaws.com/grfn-v2-ops-code-bucket/container-aria-hysds_aria-pdl-clone:master.tar.gz", 
          "version": "master"
          "dependency_images": dependency_images,
        },

        # job params
        "context_blob": job_payload, # one param - one JSON blob

        # v2 cmd
        "_command": "/home/ops/verdi/ops/SPDM-with-HySDS/run_pge.sh",

        # disk usage
        "_disk_usage": disk_usage,

        # localize urls
        "localize_urls": localize_urls,
    }
}
"""


def submit_pge_job(sf_context, runconfig, pge_config_file, settings_file, chimera_config_file,
                   wuid=None, job_num=None):
    """
    'JOBS_ES_URL'
    This function returns the job payload that needs to be mapped by sciflo
    and run on a remote worker.
    :param sf_context: context of workflow job
    :param runconfig: Run config created by input preprocessor
    :param pge_config_file: PGE's config file name
    :param settings_file:
    :param chimera_config_file:
    :param wuid: wuid of sciflo
    :param job_num: job_num in sciflo
    :return: job payload of PGE job
    """
    logger.info("Starting run_pge_docker step.")
    chimera_config = YamlConf(chimera_config_file).cfg
    module_path = chimera_config.get("job_submitter", {}).get("module_path", None)
    if not module_path:
        raise RuntimeError("'module_path' must be defined in the 'job_submitter' section of the "
                           "Chimera Config file '{}'".format(chimera_config_file))
    class_name = chimera_config.get("job_submitter", {}).get("class_name", None)
    if not class_name:
        raise RuntimeError("'class_name' must be defined in the 'job_submitter' section of the Chimera "
                           "Config file '{}'".format(chimera_config_file))
    module = import_module(module_path)
    cls = getattr(module, class_name)
    if not issubclass(cls, PgeJobSubmitter):
        raise RuntimeError("Class must be a subclass of {}: {}".format(PgeJobSubmitter.__name__,  cls.__name__))
    cls_object = cls(sf_context, runconfig, pge_config_file, settings_file, wuid, job_num)
    job_json = cls_object.submit_job()
    logger.info("Finished run_pge_docker step.")
    return job_json
